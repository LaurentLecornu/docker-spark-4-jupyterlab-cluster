services:
  spark-master:
    build: .
    container_name: spark-master
    networks:
      - network1
    ports:
      - "9080:8080"
      - "7077:7077"
      - "4040:4040"
      - "7001:7000"
      - "8888:8888"
    volumes:
       - ./apps:/opt/spark-apps
       - ./data:/opt/spark-data
       - ./spark-logs:/tmp/spark-events
    environment:
      - SPARK_LOCAL_IP=spark-master
      - SPARK_MASTER_CORES=2
      - SPARK_WORKLOAD=master
    entrypoint: /bin/bash
    command: -c "/opt/spark/sbin/start-master.sh; tail -f /dev/null"

  spark-worker-a:
    build: .
    container_name: spark-worker-a
    networks:
      - network1
    mem_limit: 1024m
    ports:
      - "9082:8080"
      - "7002:7000"
    depends_on:
      - spark-master
    environment:
      - SPARK_MASTER=spark://spark-master:7077
      - SPARK_WORKER_CORES=3
      - SPARK_WORKER_MEMORY=1G
      - SPARK_EXECUTOR_MEMORY=1G
      - SPARK_WORKLOAD=worker
      - SPARK_LOCAL_IP=spark-worker-a
    volumes:
       - ./apps:/opt/spark-apps
       - ./data:/opt/spark-data
       - ./spark-logs:/tmp/spark-events

  spark-worker-b:
    build: .
    container_name: spark-worker-b
    networks:
      - network1
    mem_limit: 1024m
    ports:
      - "9083:8080"
      - "7003:7000"
    depends_on:
      - spark-master
    environment:
      - SPARK_MASTER=spark://spark-master:7077
      - SPARK_WORKER_CORES=3
      - SPARK_WORKER_MEMORY=1G
      - SPARK_DRIVER_MEMORY=1G
      - SPARK_EXECUTOR_MEMORY=1G
      - SPARK_WORKLOAD=worker
      - SPARK_LOCAL_IP=spark-worker-b
    volumes:
        - ./apps:/opt/spark-apps
        - ./data:/opt/spark-data
        - ./spark-logs:/tmp/spark-events

  spark-worker-c:
    build: .
    container_name: spark-worker-c
    networks:
      - network1
    mem_limit: 1024m
    ports:
      - "9084:8080"
      - "7004:7000"
    depends_on:
      - spark-master
    environment:
      - SPARK_MASTER=spark://spark-master:7077
      - SPARK_WORKER_CORES=3
      - SPARK_WORKER_MEMORY=1G
      - SPARK_DRIVER_MEMORY=1G
      - SPARK_EXECUTOR_MEMORY=1G
      - SPARK_WORKLOAD=worker
      - SPARK_LOCAL_IP=spark-worker-c
    volumes:
        - ./apps:/opt/spark-apps
        - ./data:/opt/spark-data
        - ./spark-logs:/tmp/spark-events

  spark-history-server:
    build: .
    container_name: spark-history
    depends_on:
      - spark-master
    entrypoint: /bin/bash
    command: -c "/opt/spark/sbin/start-history-server.sh; tail -f /dev/null"
    volumes:
      - ./spark-logs:/tmp/spark-events
    
    ports:
      - '18080:18080'

networks:
  network1:
    name: mynetwork
    external: true
